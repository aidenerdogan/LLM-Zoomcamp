{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1136d235",
   "metadata": {},
   "source": [
    "# This Module 1 from LLM Zoomcamp from DTC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f490118d",
   "metadata": {},
   "source": [
    "## LLM Zoomcamp 1.1 - Introduction to LLM and RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a0b538",
   "metadata": {},
   "source": [
    "### LLM (Large Language Model)\n",
    "\n",
    "- Language Model: Basic language (NLP) models predict next token/word based on previous ones.\n",
    "- LLM: The LMs trained on gorges data with billion and billons of parameter which trained Neural Networks. \n",
    "\n",
    "A Large Language Model (LLM) is a type of artificial intelligence model that uses deep learning to understand and generate human language. It's trained on massive amounts of text data, allowing it to learn patterns and structures in language and perform various natural language processing (NLP) tasks. \n",
    "\n",
    "\n",
    "Here's a more detailed explanation:\n",
    "\n",
    "-  Deep Learning:\n",
    "LLMs are based on deep learning, a subfield of machine learning that uses artificial neural networks with multiple layers to analyze data and learn complex patterns. \n",
    "\n",
    "- Transformer Architecture:\n",
    "Many LLMs are built upon the Transformer architecture, which allows them to process relationships between words in a sentence, even if they're far apart. \n",
    "\n",
    "- Training Data:\n",
    "LLMs are trained on vast amounts of text, such as books, articles, and websites, to learn the nuances of language and its various forms. \n",
    "\n",
    "- Capabilities:\n",
    "LLMs can perform a wide range of NLP tasks, including:\n",
    "    Text Generation: Creating different textual formats, like poems, code, scripts, musical pieces, email, letters, etc. \n",
    "\n",
    "- Translation: Translating languages. \n",
    "    - Question Answering: Answering questions based on provided information. \n",
    "    - Summarization: Condensing large amounts of text into a shorter version. \n",
    "    - Sentiment Analysis: Determining the emotional tone of a piece of text. \n",
    "    - Code Generation: Writing code. \n",
    "\n",
    "- Applications:\n",
    "LLMs have a wide range of applications across various industries, including:\n",
    "    - Customer Service: Providing automated customer support. \n",
    "    - Content Creation: Generating marketing copy, blog posts, and other content. \n",
    "    - Research: Analyzing large datasets of text to extract insights. \n",
    "    - Education: Helping students with writing and language learning. \n",
    "In essence, LLMs are powerful tools that can understand, generate, and manipulate human language, making them valuable in many fields. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff09f3ed",
   "metadata": {},
   "source": [
    "![What is LLM](LLM-zoomcamp-whatIsLLM.drawio.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e338d8",
   "metadata": {},
   "source": [
    "### RAG (Retrieval Augmented Generation)\n",
    "\n",
    "Retrieval-Augmented Generation, is a technique in natural language processing (NLP) that combines the strengths of retrieval and generative AI models. It works by first retrieving relevant information from a knowledge base and then using a large language model (LLM) to generate a response that incorporates the retrieved data. This allows for more accurate, up-to-date, and contextually relevant outputs. \n",
    "\n",
    "Here's a more detailed breakdown:\n",
    "\n",
    "*Retrieval*: RAG utilizes search algorithms to query external data sources like databases, knowledge bases, or even the web. \n",
    "\n",
    "*Integration*: The retrieved information is then integrated with a pre-trained LLM. \n",
    "\n",
    "*Generation*: The LLM uses the retrieved data to generate a response, which can be a question answer, a summary, or even new text. \n",
    "\n",
    "Benefits of RAG:\n",
    "- Enhanced Accuracy and Relevance:\n",
    "By accessing external knowledge, RAG can generate more precise and relevant responses. \n",
    "\n",
    "- Improved Contextual Understanding:\n",
    "The retrieved information helps the LLM better understand the context of the user's query, leading to more fitting answers. \n",
    "\n",
    "- Real-time Updates:\n",
    "RAG can incorporate up-to-date information from external sources, ensuring that the generated responses are current. \n",
    "\n",
    "- Source Attributions:\n",
    "RAG can provide citations or references to the sources used to generate the response, improving trust and transparency. \n",
    "\n",
    "- Cost-Effective:\n",
    "RAG can deliver some of the benefits of a custom LLM without the high cost of retraining or fine-tuning a new model. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52cb8ba4",
   "metadata": {},
   "source": [
    "![What is RAG](LLM-zoomcamp-whatIsRAG.drawio.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c452538f",
   "metadata": {},
   "source": [
    "## LLM Zoomcamp 1.2 - Configuring Your Environment \n",
    "Will be using codespace in loacl vscode via git."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc87b77",
   "metadata": {},
   "source": [
    "1. install requierments\n",
    "'''\n",
    "bash \n",
    "pip install tqdm notebook openai elasticsearch pandas scikit-learn ipywidgets\n",
    "'''\n",
    "\n",
    "2. Generate a key in openai and export in terminal\n",
    "'''\n",
    "bash \n",
    "export OPENAI_API_KEY=\"<your key>\"\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83a2b81",
   "metadata": {},
   "source": [
    "### 1.2: Test openai api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44359672",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "token = os.environ[\"GITHUB_TOKEN\"]\n",
    "endpoint = \"https://models.github.ai/inference\"\n",
    "model = \"openai/gpt-4.1\"\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=endpoint,\n",
    "    api_key=token,\n",
    ")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful assistant.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What is the capital of France?\",\n",
    "        }\n",
    "    ],\n",
    "    temperature=1.0,\n",
    "    top_p=1.0,\n",
    "    model=model\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9a3d35-76d0-4689-a0e8-1dfc4646f91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# completion = client.chat.completions.create(\n",
    "#   model=model,\n",
    "#   messages=[\n",
    "#     {\n",
    "#       \"role\": \"user\",\n",
    "#       \"content\": \"What is the meaning of life?\"\n",
    "#     }\n",
    "#   ]\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2a422d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a8f0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = client.chat.completions.create(\n",
    "  model=model,\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"Is it toolate to join the course?\"\n",
    "    }\n",
    "  ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b274a62",
   "metadata": {},
   "source": [
    "## LLM Zoomcamp 1.3 Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040ec2c9",
   "metadata": {},
   "source": [
    "### 1.3.1 Implement a Search Engine\n",
    "\n",
    "For that go to original repo to follow\n",
    "\n",
    "#### [Build Your Own Search Engine ](https://github.com/alexeygrigorev/build-your-own-search-engine)\n",
    "\n",
    "or go to [internal folder](build_your_own_search_engine/README.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bee239f",
   "metadata": {},
   "source": [
    "Instead of building a serach engine we can continue a minimalist one buld by Alex from DTC. [Link](https://github.com/alexeygrigorev/minsearch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6e28fd",
   "metadata": {},
   "source": [
    "#### Intro to RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f4f8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import minsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a15b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "\n",
    "import requests \n",
    "\n",
    "docs_url = 'https://github.com/alexeygrigorev/llm-rag-workshop/raw/main/notebooks/documents.json'\n",
    "docs_response = requests.get(docs_url)\n",
    "documents_raw = docs_response.json()\n",
    "\n",
    "documents = []\n",
    "\n",
    "for course in documents_raw:\n",
    "    course_name = course['course']\n",
    "\n",
    "    for doc in course['documents']:\n",
    "        doc['course'] = course_name\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47f5259",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe61e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# index the documents\n",
    "# Create and fit the index\n",
    "index = minsearch.Index(\n",
    "    text_fields=[\"question\", \"text\", \"section\"],\n",
    "    keyword_fields=[\"course\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4eb1101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SELECT * WHERE course = 'data-engineering-zoomcamp';"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba57bc6",
   "metadata": {},
   "source": [
    "SELECT * WHERE course = 'data-engineering-zoomcamp';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e966bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = 'the course already started, can I still enroll?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1ce94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "index.fit(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae459c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the boost to identify importance of fields\n",
    "# the higher the value, the more important the field is\n",
    "# the default value is 1.0 for all fields\n",
    "boost = {\n",
    "    'question': 3.0, 'section': 0.5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2612823a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results  = index.search(\n",
    "    query=q,\n",
    "    boost_dict=boost,\n",
    "    num_results=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe74689",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c8c8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "results  = index.search(\n",
    "    query=q,\n",
    "    filter_dict={'course': 'data-engineering-zoomcamp'},\n",
    "    boost_dict=boost,\n",
    "    num_results=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf2ac8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa8040d",
   "metadata": {},
   "source": [
    "## LLM Zoomcamp 1.4 - Generating Answers with LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63871538",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77e42ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "token = os.environ[\"GITHUB_TOKEN\"]\n",
    "endpoint = \"https://models.github.ai/inference\"\n",
    "model = \"openai/gpt-4.1\"\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=endpoint,\n",
    "    api_key=token,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a35079",
   "metadata": {},
   "outputs": [],
   "source": [
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d93fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": q}\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bdf744",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2e6303",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "PROMPT:\n",
    "You are a course teaching assistant.\n",
    "Your task is to help students with their questions about the course material based on the context provided from the FAQ database.\n",
    "Use only the context to answer the questions. If the context does not provide enough information, respond with \"I don't know\" or \"I don't have enough information to answer that question.\"\n",
    "Be polite and concise in your responses.\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "CONTEXT:\n",
    "{context}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154eae77",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27024bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"\"\n",
    "\n",
    "for doc in results:\n",
    "    context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2688e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134fc9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = prompt_template.format(question=q, context=context).strip()\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce00129",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16ef595",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8870314",
   "metadata": {},
   "source": [
    "## LLM Zoomcamp 1.5 - The RAG Flow Cleaning and Modularizing Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878e4f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query):\n",
    "\n",
    "    boost = {\n",
    "        'question': 3.0,\n",
    "        'section': 0.5\n",
    "    }\n",
    "\n",
    "    # Search the index with the query and boost\n",
    "    # Filter by course if needed\n",
    "    # For example, if you want to filter by 'data-engineering-zoomcamp'\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict={'course': 'data-engineering-zoomcamp'},\n",
    "        boost_dict=boost,\n",
    "        num_results=5\n",
    "    )\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9c8aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(query, search_results):\n",
    "\n",
    "    prompt_template = \"\"\"\n",
    "    PROMPT:\n",
    "    You are a course teaching assistant.\n",
    "    Your task is to help students with their questions about the course material based on the context provided from the FAQ database.\n",
    "    Use only the context to answer the questions. If the context does not provide enough information, respond with \"I don't know\" or \"I don't have enough information to answer that question.\"\n",
    "    Be polite and concise in your responses.\n",
    "\n",
    "    QUESTION: {question}\n",
    "\n",
    "    CONTEXT:\n",
    "    {context}\n",
    "    \"\"\".strip()\n",
    "\n",
    "    context = \"\"\n",
    "\n",
    "    for doc in search_results:\n",
    "        context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\"\n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    \n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac35b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "token = os.environ[\"GITHUB_TOKEN\"]\n",
    "endpoint = \"https://models.github.ai/inference\"\n",
    "model = \"openai/gpt-4.1\"\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=endpoint,\n",
    "    api_key=token,\n",
    ")\n",
    "\n",
    "def llm(prompt):\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ea2180",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"How do I run Kafka?\"\n",
    "\n",
    "def rag(query):\n",
    "    \"\"\"\n",
    "    Run the RAG process: search, build prompt, and get answer from LLM.\n",
    "    \"\"\"\n",
    "    # Search for relevant documents\n",
    "    search_results = search(query)\n",
    "\n",
    "    prompt = (build_prompt(query, search_results))\n",
    "\n",
    "    answer = llm(prompt)\n",
    "\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e8f108",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag(\"The course already started, can I still enroll?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fca083b",
   "metadata": {},
   "source": [
    "## LLM Zoomcamp 1.6 - Search with Elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38fc27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1ebd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install \"elasticsearch==8.4.3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcce50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "es_client = Elasticsearch('http://localhost:9200')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543caf65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # elasticsearch container with lower memory limits\n",
    "\n",
    "# docker run -it \\\n",
    "#   --rm \\\n",
    "#   --name elasticsearch \\\n",
    "#   -p 9200:9200 \\\n",
    "#   -p 9300:9300 \\\n",
    "#   -e \"discovery.type=single-node\" \\\n",
    "#   -e \"xpack.security.enabled=false\" \\\n",
    "#   -e \"ES_JAVA_OPTS=-Xms512m -Xmx512m\" \\\n",
    "#   elasticsearch:8.4.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be265c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "es_client.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e91168",
   "metadata": {
    "vscode": {
     "languageId": "javascript"
    }
   },
   "outputs": [],
   "source": [
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"text\": {\"type\": \"text\"},\n",
    "            \"section\": {\"type\": \"text\"},\n",
    "            \"question\": {\"type\": \"text\"},\n",
    "            \"course\": {\"type\": \"keyword\"} \n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "index_name = \"course-questions\"\n",
    "\n",
    "es_client.indices.create(\n",
    "    index=index_name,\n",
    "    body=index_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c420d79b",
   "metadata": {
    "vscode": {
     "languageId": "javascript"
    }
   },
   "outputs": [],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf8c08d",
   "metadata": {
    "vscode": {
     "languageId": "javascript"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "452523d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in tqdm(documents):\n",
    "    es_client.index(index=index_name,document=doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d2d36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef6dd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"I just discovered the course, can I still enroll?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d91e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_query = {\n",
    "    \"size\": 5,\n",
    "    \"query\": {\n",
    "        \"bool\": {\n",
    "            \"must\": {\n",
    "                \"multi_match\": {\n",
    "                    \"query\": query,\n",
    "                    \"fields\": [\"question^3\", \"text\", \"section\"],\n",
    "                    \"type\": \"best_fields\"\n",
    "                }\n",
    "            },\n",
    "            \"filter\": {\n",
    "                \"term\": {\n",
    "                    \"course\": \"data-engineering-zoomcamp\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1d270e",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = es_client.search(\n",
    "    index=index_name,\n",
    "    body=search_query\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfbc043",
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ba6ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "response['hits']['hits'][0]['_source']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b277da",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_docs = []\n",
    "\n",
    "for hit in response['hits']['hits']:\n",
    "    results_docs.append(hit['_source'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8acafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91fa036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up 1.6\n",
    "\n",
    "def elasric_search(query):\n",
    "    search_query = {\n",
    "        \"size\": 5,\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"must\": {\n",
    "                    \"multi_match\": {\n",
    "                        \"query\": query,\n",
    "                        \"fields\": [\"question^3\", \"text\", \"section\"],\n",
    "                        \"type\": \"best_fields\"\n",
    "                    }\n",
    "                },\n",
    "                \"filter\": {\n",
    "                    \"term\": {\n",
    "                        \"course\": \"data-engineering-zoomcamp\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "\n",
    "    response = es_client.search(\n",
    "        index=index_name,\n",
    "        body=search_query\n",
    "    )\n",
    "\n",
    "\n",
    "    results_docs = []\n",
    "\n",
    "    for hit in response['hits']['hits']:\n",
    "        results_docs.append(hit['_source'])\n",
    "\n",
    "    return results_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a775abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "elasric_search(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345bdbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(query):\n",
    "    \"\"\"\n",
    "    Run the RAG process: search, build prompt, and get answer from LLM.\n",
    "    \"\"\"\n",
    "    # Search for relevant documents\n",
    "    search_results = elasric_search(query)\n",
    "\n",
    "    prompt = (build_prompt(query, search_results))\n",
    "\n",
    "    answer = llm(prompt)\n",
    "\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f943e716",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8b2341",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddd4a20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
