{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1136d235",
   "metadata": {},
   "source": [
    "# This Module 1 from LLM Zoomcamp from DTC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f490118d",
   "metadata": {},
   "source": [
    "## LLM Zoomcamp 1.1 - Introduction to LLM and RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a0b538",
   "metadata": {},
   "source": [
    "### LLM (Large Language Model)\n",
    "\n",
    "- Language Model: Basic language (NLP) models predict next token/word based on previous ones.\n",
    "- LLM: The LMs trained on gorges data with billion and billons of parameter which trained Neural Networks. \n",
    "\n",
    "A Large Language Model (LLM) is a type of artificial intelligence model that uses deep learning to understand and generate human language. It's trained on massive amounts of text data, allowing it to learn patterns and structures in language and perform various natural language processing (NLP) tasks. \n",
    "\n",
    "\n",
    "Here's a more detailed explanation:\n",
    "\n",
    "-  Deep Learning:\n",
    "LLMs are based on deep learning, a subfield of machine learning that uses artificial neural networks with multiple layers to analyze data and learn complex patterns. \n",
    "\n",
    "- Transformer Architecture:\n",
    "Many LLMs are built upon the Transformer architecture, which allows them to process relationships between words in a sentence, even if they're far apart. \n",
    "\n",
    "- Training Data:\n",
    "LLMs are trained on vast amounts of text, such as books, articles, and websites, to learn the nuances of language and its various forms. \n",
    "\n",
    "- Capabilities:\n",
    "LLMs can perform a wide range of NLP tasks, including:\n",
    "    Text Generation: Creating different textual formats, like poems, code, scripts, musical pieces, email, letters, etc. \n",
    "\n",
    "- Translation: Translating languages. \n",
    "    - Question Answering: Answering questions based on provided information. \n",
    "    - Summarization: Condensing large amounts of text into a shorter version. \n",
    "    - Sentiment Analysis: Determining the emotional tone of a piece of text. \n",
    "    - Code Generation: Writing code. \n",
    "\n",
    "- Applications:\n",
    "LLMs have a wide range of applications across various industries, including:\n",
    "    - Customer Service: Providing automated customer support. \n",
    "    - Content Creation: Generating marketing copy, blog posts, and other content. \n",
    "    - Research: Analyzing large datasets of text to extract insights. \n",
    "    - Education: Helping students with writing and language learning. \n",
    "In essence, LLMs are powerful tools that can understand, generate, and manipulate human language, making them valuable in many fields. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff09f3ed",
   "metadata": {},
   "source": [
    "![What is LLM](/module1/LLM-zoomcamp-whatIsLLM.drawio.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08e338d8",
   "metadata": {},
   "source": [
    "### RAG (Retrieval Augmented Generation)\n",
    "\n",
    "Retrieval-Augmented Generation, is a technique in natural language processing (NLP) that combines the strengths of retrieval and generative AI models. It works by first retrieving relevant information from a knowledge base and then using a large language model (LLM) to generate a response that incorporates the retrieved data. This allows for more accurate, up-to-date, and contextually relevant outputs. \n",
    "\n",
    "Here's a more detailed breakdown:\n",
    "\n",
    "*Retrieval*: RAG utilizes search algorithms to query external data sources like databases, knowledge bases, or even the web. \n",
    "\n",
    "*Integration*: The retrieved information is then integrated with a pre-trained LLM. \n",
    "\n",
    "*Generation*: The LLM uses the retrieved data to generate a response, which can be a question answer, a summary, or even new text. \n",
    "\n",
    "Benefits of RAG:\n",
    "- Enhanced Accuracy and Relevance:\n",
    "By accessing external knowledge, RAG can generate more precise and relevant responses. \n",
    "\n",
    "- Improved Contextual Understanding:\n",
    "The retrieved information helps the LLM better understand the context of the user's query, leading to more fitting answers. \n",
    "\n",
    "- Real-time Updates:\n",
    "RAG can incorporate up-to-date information from external sources, ensuring that the generated responses are current. \n",
    "\n",
    "- Source Attributions:\n",
    "RAG can provide citations or references to the sources used to generate the response, improving trust and transparency. \n",
    "\n",
    "- Cost-Effective:\n",
    "RAG can deliver some of the benefits of a custom LLM without the high cost of retraining or fine-tuning a new model. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52cb8ba4",
   "metadata": {},
   "source": [
    "![What is RAG](/module1/LLM-zoomcamp-whatIsRAG.drawio.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c452538f",
   "metadata": {},
   "source": [
    "## LLM Zoomcamp 1.2 - Configuring Your Environment\n",
    "Will be using codespace in loacl vscode v≈üa git."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc87b77",
   "metadata": {},
   "source": [
    "1. install requierments\n",
    "'''\n",
    "bash \n",
    "pip install pip install tqdm notebook openai elasticsearch scikit-learn pandas\n",
    "'''\n",
    "\n",
    "2. Generate a key in openai and export in terminal\n",
    "'''\n",
    "bash \n",
    "export OPENAI_API_KEY=\"<your key>\"\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83a2b81",
   "metadata": {},
   "source": [
    "### 1.2: Test openai api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36147cda",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05048480",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
